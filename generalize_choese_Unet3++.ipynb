{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tranngocduvnvp/CTCDFormer/blob/main/CTDCFormerB4.ipynb)"
      ],
      "metadata": {
        "id": "6f3fsn18kLTB",
        "papermill": {
          "duration": 0.010643,
          "end_time": "2022-12-21T01:08:29.557950",
          "exception": false,
          "start_time": "2022-12-21T01:08:29.547307",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "vKnxAEbb4vo7",
        "outputId": "34ac3a72-359b-40e0-a4ca-8148c31020de",
        "papermill": {
          "duration": 12.839045,
          "end_time": "2022-12-21T01:08:42.406289",
          "exception": false,
          "start_time": "2022-12-21T01:08:29.567244",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:45:56.881825Z",
          "iopub.execute_input": "2023-01-18T12:45:56.882528Z",
          "iopub.status.idle": "2023-01-18T12:46:11.658187Z",
          "shell.execute_reply.started": "2023-01-18T12:45:56.882417Z",
          "shell.execute_reply": "2023-01-18T12:46:11.657137Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.1+cu116)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.12.0 timm-0.6.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchgeometry"
      ],
      "metadata": {
        "id": "GR0N1x9yDs6G",
        "outputId": "ebe1263c-86db-4144-afce-28db7d2422d3",
        "papermill": {
          "duration": 10.601966,
          "end_time": "2022-12-21T01:08:53.019161",
          "exception": false,
          "start_time": "2022-12-21T01:08:42.417195",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:46:11.661738Z",
          "iopub.execute_input": "2023-01-18T12:46:11.662054Z",
          "iopub.status.idle": "2023-01-18T12:46:21.592517Z",
          "shell.execute_reply.started": "2023-01-18T12:46:11.662026Z",
          "shell.execute_reply": "2023-01-18T12:46:21.591415Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchgeometry\n",
            "  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from torchgeometry) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->torchgeometry) (4.4.0)\n",
            "Installing collected packages: torchgeometry\n",
            "Successfully installed torchgeometry-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "fP9t9fQ446Jm",
        "outputId": "d0e99979-be54-4f74-adc4-6af63084deeb",
        "papermill": {
          "duration": 9.737912,
          "end_time": "2022-12-21T01:09:02.769811",
          "exception": false,
          "start_time": "2022-12-21T01:08:53.031899",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:46:21.596266Z",
          "iopub.execute_input": "2023-01-18T12:46:21.596591Z",
          "iopub.status.idle": "2023-01-18T12:46:31.132696Z",
          "shell.execute_reply.started": "2023-01-18T12:46:21.596563Z",
          "shell.execute_reply": "2023-01-18T12:46:31.131461Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade gdown"
      ],
      "metadata": {
        "id": "t2eIKy8oM4gU",
        "outputId": "81189c69-d106-44ee-ceb3-33eb60ad6df1",
        "papermill": {
          "duration": 10.891759,
          "end_time": "2022-12-21T01:09:13.673967",
          "exception": false,
          "start_time": "2022-12-21T01:09:02.782208",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:46:31.135820Z",
          "iopub.execute_input": "2023-01-18T12:46:31.136560Z",
          "iopub.status.idle": "2023-01-18T12:46:41.748487Z",
          "shell.execute_reply.started": "2023-01-18T12:46:31.136518Z",
          "shell.execute_reply": "2023-01-18T12:46:41.747131Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install texttable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFpuisVXI3xF",
        "outputId": "48845b93-3fe3-42fb-ed07-18837add0033"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.6.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1wKiVxrOWtn2JjTMXNoED2FGsT98AMKW6"
      ],
      "metadata": {
        "id": "ngXq172EEgXu",
        "outputId": "0bd2ea18-326e-45d0-d627-f16246019afb",
        "papermill": {
          "duration": 34.878693,
          "end_time": "2022-12-21T01:09:48.564332",
          "exception": false,
          "start_time": "2022-12-21T01:09:13.685639",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:46:41.750687Z",
          "iopub.execute_input": "2023-01-18T12:46:41.751091Z",
          "iopub.status.idle": "2023-01-18T12:46:48.806098Z",
          "shell.execute_reply.started": "2023-01-18T12:46:41.751050Z",
          "shell.execute_reply": "2023-01-18T12:46:48.804824Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wKiVxrOWtn2JjTMXNoED2FGsT98AMKW6\n",
            "To: /content/data_new.zip\n",
            "100% 399M/399M [00:03<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./data_new.zip"
      ],
      "metadata": {
        "id": "HLlUGUUfMG9h",
        "papermill": {
          "duration": 8.298948,
          "end_time": "2022-12-21T01:09:56.884141",
          "exception": false,
          "start_time": "2022-12-21T01:09:48.585193",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:48:34.996415Z",
          "iopub.execute_input": "2023-01-18T12:48:34.996833Z",
          "iopub.status.idle": "2023-01-18T12:48:39.321201Z",
          "shell.execute_reply.started": "2023-01-18T12:48:34.996800Z",
          "shell.execute_reply": "2023-01-18T12:48:39.320039Z"
        },
        "scrolled": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b2.pth\n",
        "# !wget https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b3.pth\n",
        "# !wget https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b4.pth"
      ],
      "metadata": {
        "id": "qOR3AUMN8sz2",
        "papermill": {
          "duration": 127.297421,
          "end_time": "2022-12-21T01:12:04.214574",
          "exception": false,
          "start_time": "2022-12-21T01:09:56.917153",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:48:53.056405Z",
          "iopub.execute_input": "2023-01-18T12:48:53.056795Z",
          "iopub.status.idle": "2023-01-18T12:48:59.672155Z",
          "shell.execute_reply.started": "2023-01-18T12:48:53.056764Z",
          "shell.execute_reply": "2023-01-18T12:48:59.670503Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torchvision.transforms.functional as TF\n",
        "import numpy as np\n",
        "import random\n",
        "import multiprocessing\n",
        "import timm\n",
        "import torchmetrics\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchmetrics.functional.classification as Fmstric\n",
        "import torchgeometry as tgm\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "from timm.models.vision_transformer import _cfg\n",
        "from texttable import Texttable\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "iJQo-R7N4vo_",
        "papermill": {
          "duration": 4.856272,
          "end_time": "2022-12-21T01:12:09.136484",
          "exception": false,
          "start_time": "2022-12-21T01:12:04.280212",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:48:59.676093Z",
          "iopub.execute_input": "2023-01-18T12:48:59.680365Z",
          "iopub.status.idle": "2023-01-18T12:48:59.701343Z",
          "shell.execute_reply.started": "2023-01-18T12:48:59.680308Z",
          "shell.execute_reply": "2023-01-18T12:48:59.699854Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self,root, epochs, batch_size, dataset, mgpu, lrs_min,\\\n",
        "                 lrs, lr, type_lr, checkpoint_path, backbone, optim):\n",
        "        self.root = root\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset = dataset\n",
        "        self.mgpu = mgpu\n",
        "        self.lrs_min = lrs_min\n",
        "        self.lrs = lrs\n",
        "        self.lr = lr\n",
        "        self.type_lr = type_lr\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.backbone = backbone\n",
        "        self.optim = optim\n",
        "        \n",
        "args = Args(\n",
        "    root=\"./data_new\", \n",
        "    epochs=80, \n",
        "    batch_size=4, \n",
        "    dataset=\"generalizability_Unet3\",\n",
        "    mgpu=\"false\",\n",
        "    lrs=\"true\",\n",
        "    lrs_min=1e-6,\n",
        "    lr = 3e-4,\n",
        "    type_lr = \"StepLR\",\n",
        "    checkpoint_path = None,\n",
        "    backbone=\"PvtB3\",\n",
        "    optim=\"Adam\"\n",
        ")\n",
        "args.root"
      ],
      "metadata": {
        "id": "tBmoDkE84vpA",
        "outputId": "e6e6bbde-a93c-46d7-84d3-458cd1a1fe64",
        "papermill": {
          "duration": 0.115313,
          "end_time": "2022-12-21T01:12:09.369476",
          "exception": false,
          "start_time": "2022-12-21T01:12:09.254163",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:08.479773Z",
          "iopub.execute_input": "2023-01-18T12:52:08.480239Z",
          "iopub.status.idle": "2023-01-18T12:52:08.493805Z",
          "shell.execute_reply.started": "2023-01-18T12:52:08.480201Z",
          "shell.execute_reply": "2023-01-18T12:52:08.492642Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./data_new'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Dataset"
      ],
      "metadata": {
        "id": "YXobI07G4vpB",
        "papermill": {
          "duration": 0.111726,
          "end_time": "2022-12-21T01:12:09.589827",
          "exception": false,
          "start_time": "2022-12-21T01:12:09.478101",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegDataset(data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_paths: list,\n",
        "        target_paths: list,\n",
        "        transform_input=None,\n",
        "        transform_target=None,\n",
        "        hflip=False,\n",
        "        vflip=False,\n",
        "        affine=False,\n",
        "    ):\n",
        "        self.input_paths = input_paths\n",
        "        self.target_paths = target_paths\n",
        "        self.transform_input = transform_input\n",
        "        self.transform_target = transform_target\n",
        "        self.hflip = hflip\n",
        "        self.vflip = vflip\n",
        "        self.affine = affine\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        input_ID = self.input_paths[index]\n",
        "        target_ID = self.target_paths[index]\n",
        "\n",
        "        x = cv2.cvtColor(cv2.imread(input_ID), cv2.COLOR_BGR2RGB)\n",
        "        y = cv2.cvtColor(cv2.imread(target_ID), cv2.COLOR_BGR2RGB)\n",
        "        x = self.transform_input(x)\n",
        "        y = self.transform_target(y)\n",
        "\n",
        "        if self.hflip:\n",
        "            if random.uniform(0.0, 1.0) > 0.5:\n",
        "                x = TF.hflip(x)\n",
        "                y = TF.hflip(y)\n",
        "\n",
        "        if self.vflip:\n",
        "            if random.uniform(0.0, 1.0) > 0.5:\n",
        "                x = TF.vflip(x)\n",
        "                y = TF.vflip(y)\n",
        "\n",
        "        if self.affine:\n",
        "            angle = random.uniform(-180.0, 180.0)\n",
        "            h_trans = random.uniform(-352 / 8, 352 / 8)\n",
        "            v_trans = random.uniform(-352 / 8, 352 / 8)\n",
        "            scale = random.uniform(0.5, 1.5)\n",
        "            shear = random.uniform(-22.5, 22.5)\n",
        "            x = TF.affine(x, angle, (h_trans, v_trans), scale, shear, fill=-1.0)\n",
        "            y = TF.affine(y, angle, (h_trans, v_trans), scale, shear, fill=0.0)\n",
        "        return x.float(), y.float()\n",
        "\n"
      ],
      "metadata": {
        "id": "s3GSDxe34vpD",
        "papermill": {
          "duration": 0.115216,
          "end_time": "2022-12-21T01:12:09.798794",
          "exception": false,
          "start_time": "2022-12-21T01:12:09.683578",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:15.370431Z",
          "iopub.execute_input": "2023-01-18T12:52:15.370794Z",
          "iopub.status.idle": "2023-01-18T12:52:15.383276Z",
          "shell.execute_reply.started": "2023-01-18T12:52:15.370765Z",
          "shell.execute_reply": "2023-01-18T12:52:15.382185Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_ids(len_ids):\n",
        "    train_size = int(round((80 / 100) * len_ids))\n",
        "    valid_size = int(round((10 / 100) * len_ids))\n",
        "    test_size = int(round((10 / 100) * len_ids))\n",
        "\n",
        "    train_indices, test_indices = train_test_split(\n",
        "        np.linspace(0, len_ids - 1, len_ids).astype(\"int\"),\n",
        "        test_size=test_size,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        train_indices, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    return train_indices, test_indices, val_indices\n",
        "\n",
        "\n",
        "def get_dataloaders(root_train, root_test, batch_size):\n",
        "    input_paths_train = sorted(glob.glob(root_train + \"/images/*\"))\n",
        "    target_path_train = sorted(glob.glob(root_train + \"/masks/*\"))\n",
        "    dataset_test = [\"Kvasir\", \"ETIS-LaribPolypDB\", \"CVC-ColonDB\", \"CVC-ClinicDB\",\"CVC-300\"]\n",
        "    path_image_test = {}\n",
        "    path_mask_test = {}\n",
        "    for item_name in dataset_test:\n",
        "        path_image_test[item_name] = sorted(glob.glob(root_test + f\"/{item_name}\" + \"/images/*\"))\n",
        "        path_mask_test[item_name] = sorted(glob.glob(root_test + f\"/{item_name}\" + \"/masks/*\"))\n",
        "\n",
        "    transform_input4train = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((352, 352), antialias=True),\n",
        "            transforms.GaussianBlur((25, 25), sigma=(0.001, 2.0)),\n",
        "            transforms.ColorJitter(\n",
        "                brightness=0.4, contrast=0.5, saturation=0.25, hue=0.01\n",
        "            ),\n",
        "            transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    transform_input4test = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((352, 352), antialias=True),\n",
        "            transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    transform_target = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Resize((352, 352)), transforms.Grayscale()]\n",
        "    )\n",
        "\n",
        "    train_dataset = SegDataset(\n",
        "        input_paths=input_paths_train,\n",
        "        target_paths=target_path_train,\n",
        "        transform_input=transform_input4train,\n",
        "        transform_target=transform_target,\n",
        "        hflip=True,\n",
        "        vflip=True,\n",
        "        affine=True,\n",
        "    )\n",
        "    test_dataset = {}\n",
        "    for item in path_image_test:\n",
        "      test_dataset[item] = SegDataset(\n",
        "        input_paths=path_image_test[item],\n",
        "        target_paths=path_mask_test[item],\n",
        "        transform_input=transform_input4test,\n",
        "        transform_target=transform_target,)\n",
        "\n",
        "    \n",
        "    train_dataloader = data.DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=multiprocessing.Pool()._processes,\n",
        "    )\n",
        "    test_dataloader = {}\n",
        "    for item in test_dataset:\n",
        "      test_dataloader[item] = data.DataLoader(\n",
        "        dataset=test_dataset[item],\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=multiprocessing.Pool()._processes,)\n",
        "\n",
        "\n",
        "\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "\n",
        "root_train = \"./data_new/TrainDataset\"\n",
        "root_test = \"./data_new/TestDataset\"\n",
        "train_dataloader, test_dataloader = get_dataloaders(\n",
        "    root_train,\n",
        "    root_test,\n",
        "    4\n",
        ")\n",
        "        \n",
        "image, mask = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "CpOv-X1-4vpF",
        "papermill": {
          "duration": 3.847189,
          "end_time": "2022-12-21T01:12:13.748084",
          "exception": false,
          "start_time": "2022-12-21T01:12:09.900895",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(img, mask):\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img[0].permute(1,2,0))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask[0][0], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "metadata": {
        "id": "0cRw35_oabyY",
        "papermill": {
          "duration": 0.19377,
          "end_time": "2022-12-21T01:12:14.034924",
          "exception": false,
          "start_time": "2022-12-21T01:12:13.841154",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:15.492375Z",
          "iopub.status.idle": "2023-01-18T12:52:15.493667Z",
          "shell.execute_reply.started": "2023-01-18T12:52:15.493395Z",
          "shell.execute_reply": "2023-01-18T12:52:15.493421Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, mask = next(iter(test_dataloader[\"ETIS-LaribPolypDB\"])) \n",
        "show(image, mask)"
      ],
      "metadata": {
        "id": "Qr3WFOsOaHJH",
        "outputId": "2ef247c1-8666-417e-82c0-d0ad98167d41",
        "papermill": {
          "duration": 0.788602,
          "end_time": "2022-12-21T01:12:14.892760",
          "exception": false,
          "start_time": "2022-12-21T01:12:14.104158",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:15.495370Z",
          "iopub.status.idle": "2023-01-18T12:52:15.495876Z",
          "shell.execute_reply.started": "2023-01-18T12:52:15.495614Z",
          "shell.execute_reply": "2023-01-18T12:52:15.495638Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make model"
      ],
      "metadata": {
        "id": "WrpFsb-E4vpH",
        "papermill": {
          "duration": 0.062283,
          "end_time": "2022-12-21T01:12:15.041138",
          "exception": false,
          "start_time": "2022-12-21T01:12:14.978855",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backbone"
      ],
      "metadata": {
        "id": "2qtOlRLS4vpI",
        "papermill": {
          "duration": 0.094451,
          "end_time": "2022-12-21T01:12:15.195241",
          "exception": false,
          "start_time": "2022-12-21T01:12:15.100790",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIT"
      ],
      "metadata": {
        "id": "YoZzR-Ru6OfG",
        "papermill": {
          "duration": 0.062869,
          "end_time": "2022-12-21T01:12:15.322986",
          "exception": false,
          "start_time": "2022-12-21T01:12:15.260117",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "from functools import partial\n",
        "from timm.models.layers import to_2tuple, trunc_normal_\n",
        "import math\n",
        "from timm.models.layers import DropPath\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.dwconv = DWConv(hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dwconv(x, H, W)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., sr_ratio=1):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "        self.kv = nn.Linear(dim, dim * 2, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        self.sr_ratio = sr_ratio\n",
        "        if sr_ratio > 1:\n",
        "            self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)\n",
        "            self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, N, C = x.shape\n",
        "        q = self.q(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
        "\n",
        "        if self.sr_ratio > 1:\n",
        "            x_ = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "            x_ = self.sr(x_).reshape(B, C, -1).permute(0, 2, 1)\n",
        "            x_ = self.norm(x_)\n",
        "            kv = self.kv(x_).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        else:\n",
        "            kv = self.kv(x).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        k, v = kv[0], kv[1]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, sr_ratio=1):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "            dim,\n",
        "            num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop, proj_drop=drop, sr_ratio=sr_ratio)\n",
        "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x), H, W))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x), H, W))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class OverlapPatchEmbed(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=7, stride=4, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        img_size = to_2tuple(img_size)\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.H, self.W = img_size[0] // patch_size[0], img_size[1] // patch_size[1]\n",
        "        self.num_patches = self.H * self.W\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride,\n",
        "                              padding=(patch_size[0] // 2, patch_size[1] // 2))\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        _, _, H, W = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        return x, H, W\n",
        "\n",
        "\n",
        "class MixVisionTransformer(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dims=[64, 128, 256, 512],\n",
        "                 num_heads=[1, 2, 4, 8], mlp_ratios=[4, 4, 4, 4], qkv_bias=False, qk_scale=None, drop_rate=0.,\n",
        "                 attn_drop_rate=0., drop_path_rate=0., norm_layer=nn.LayerNorm,\n",
        "                 depths=[3, 4, 6, 3], sr_ratios=[8, 4, 2, 1]):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.depths = depths\n",
        "        self.embed_dims = embed_dims\n",
        "\n",
        "        # patch_embed\n",
        "        self.patch_embed1 = OverlapPatchEmbed(img_size=img_size, patch_size=7, stride=4, in_chans=in_chans,\n",
        "                                              embed_dim=embed_dims[0])\n",
        "        self.patch_embed2 = OverlapPatchEmbed(img_size=img_size // 4, patch_size=3, stride=2, in_chans=embed_dims[0],\n",
        "                                              embed_dim=embed_dims[1])\n",
        "        self.patch_embed3 = OverlapPatchEmbed(img_size=img_size // 8, patch_size=3, stride=2, in_chans=embed_dims[1],\n",
        "                                              embed_dim=embed_dims[2])\n",
        "        self.patch_embed4 = OverlapPatchEmbed(img_size=img_size // 16, patch_size=3, stride=2, in_chans=embed_dims[2],\n",
        "                                              embed_dim=embed_dims[3])\n",
        "\n",
        "        # transformer encoder\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
        "        cur = 0\n",
        "        self.block1 = nn.ModuleList([Block(\n",
        "            dim=embed_dims[0], num_heads=num_heads[0], mlp_ratio=mlp_ratios[0], qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "            drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[cur + i], norm_layer=norm_layer,\n",
        "            sr_ratio=sr_ratios[0])\n",
        "            for i in range(depths[0])])\n",
        "        self.norm1 = norm_layer(embed_dims[0])\n",
        "\n",
        "        cur += depths[0]\n",
        "        self.block2 = nn.ModuleList([Block(\n",
        "            dim=embed_dims[1], num_heads=num_heads[1], mlp_ratio=mlp_ratios[1], qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "            drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[cur + i], norm_layer=norm_layer,\n",
        "            sr_ratio=sr_ratios[1])\n",
        "            for i in range(depths[1])])\n",
        "        self.norm2 = norm_layer(embed_dims[1])\n",
        "\n",
        "        cur += depths[1]\n",
        "        self.block3 = nn.ModuleList([Block(\n",
        "            dim=embed_dims[2], num_heads=num_heads[2], mlp_ratio=mlp_ratios[2], qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "            drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[cur + i], norm_layer=norm_layer,\n",
        "            sr_ratio=sr_ratios[2])\n",
        "            for i in range(depths[2])])\n",
        "        self.norm3 = norm_layer(embed_dims[2])\n",
        "\n",
        "        cur += depths[2]\n",
        "        self.block4 = nn.ModuleList([Block(\n",
        "            dim=embed_dims[3], num_heads=num_heads[3], mlp_ratio=mlp_ratios[3], qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "            drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[cur + i], norm_layer=norm_layer,\n",
        "            sr_ratio=sr_ratios[3])\n",
        "            for i in range(depths[3])])\n",
        "        self.norm4 = norm_layer(embed_dims[3])\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "        outs = []\n",
        "\n",
        "        # stage 1\n",
        "        x, H, W = self.patch_embed1(x)\n",
        "        for i, blk in enumerate(self.block1):\n",
        "            x = blk(x, H, W)\n",
        "        x = self.norm1(x)\n",
        "        x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
        "        outs.append(x)\n",
        "\n",
        "        # stage 2\n",
        "        x, H, W = self.patch_embed2(x)\n",
        "        for i, blk in enumerate(self.block2):\n",
        "            x = blk(x, H, W)\n",
        "        x = self.norm2(x)\n",
        "        x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
        "        outs.append(x)\n",
        "\n",
        "        # stage 3\n",
        "        x, H, W = self.patch_embed3(x)\n",
        "        for i, blk in enumerate(self.block3):\n",
        "            x = blk(x, H, W)\n",
        "        x = self.norm3(x)\n",
        "        x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
        "        outs.append(x)\n",
        "\n",
        "        # stage 4\n",
        "        x, H, W = self.patch_embed4(x)\n",
        "        for i, blk in enumerate(self.block4):\n",
        "            x = blk(x, H, W)\n",
        "        x = self.norm4(x)\n",
        "        x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
        "        outs.append(x)\n",
        "\n",
        "        return outs\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DWConv(nn.Module):\n",
        "    def __init__(self, dim=768):\n",
        "        super(DWConv, self).__init__()\n",
        "        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, N, C = x.shape\n",
        "        x = x.transpose(1, 2).view(B, C, H, W)\n",
        "        x = self.dwconv(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class mit_b0(MixVisionTransformer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(mit_b0, self).__init__(\n",
        "            patch_size=4, embed_dims=[32, 64, 160, 256], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4],\n",
        "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[2, 2, 2, 2], sr_ratios=[8, 4, 2, 1],\n",
        "            drop_rate=0.0, drop_path_rate=0.1)\n",
        "\n",
        "\n",
        "class mit_b1(MixVisionTransformer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(mit_b1, self).__init__(\n",
        "            patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4],\n",
        "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[2, 2, 2, 2], sr_ratios=[8, 4, 2, 1],\n",
        "            drop_rate=0.0, drop_path_rate=0.1)\n",
        "\n",
        "\n",
        "class mit_b2(MixVisionTransformer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(mit_b2, self).__init__(\n",
        "            patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4],\n",
        "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 4, 6, 3], sr_ratios=[8, 4, 2, 1],\n",
        "            drop_rate=0.0, drop_path_rate=0.1)\n",
        "\n",
        "\n",
        "class mit_b3(MixVisionTransformer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(mit_b3, self).__init__(\n",
        "            patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4],\n",
        "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 4, 18, 3], sr_ratios=[8, 4, 2, 1],\n",
        "            drop_rate=0.0, drop_path_rate=0.1)\n",
        "\n",
        "\n",
        "class mit_b4(MixVisionTransformer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(mit_b4, self).__init__(\n",
        "            patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4],\n",
        "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 8, 27, 3], sr_ratios=[8, 4, 2, 1],\n",
        "            drop_rate=0.0, drop_path_rate=0.1)\n",
        "\n",
        "\n",
        "class mit_b5(MixVisionTransformer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(mit_b5, self).__init__(\n",
        "            patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4],\n",
        "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 6, 40, 3], sr_ratios=[8, 4, 2, 1],\n",
        "            drop_rate=0.0, drop_path_rate=0.1)\n",
        "        \n",
        "class Feature_extractor_MIT(nn.Module):\n",
        "\n",
        "    def __init__(self,model_type=\"MitB0\", embedding_dim = 160):\n",
        "        super(Feature_extractor_MIT, self).__init__()\n",
        "        self.model_type = model_type\n",
        "        # Backbone\n",
        "        if self.model_type == 'MitB0':\n",
        "            self.backbone = mit_b0()\n",
        "            self.channel = [32, 64, 160, 256]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if self.model_type == 'MitB1':\n",
        "            self.backbone = mit_b1()\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if self.model_type == 'MitB2':\n",
        "            self.backbone = mit_b2()\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if self.model_type == 'MitB3':\n",
        "            self.backbone = mit_b3()\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if self.model_type == 'MitB4':\n",
        "            self.backbone = mit_b4()\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if self.model_type == 'MitB5':\n",
        "            self.backbone = mit_b5()\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        self._init_weights()  # load pretrain\n",
        "        \n",
        "        \n",
        "    def _init_weights(self):\n",
        "        \n",
        "        if self.model_type == 'MitB0':\n",
        "            pretrained_dict = torch.load('./Pretrained/mit_b0.pth')\n",
        "        if self.model_type == 'MitB1':\n",
        "            pretrained_dict = torch.load('./Pretrained/mit_b1.pth')\n",
        "        if self.model_type == 'MitB2':\n",
        "            pretrained_dict = torch.load('./Pretrained/mit_b2.pth')\n",
        "        if self.model_type == 'MitB3':\n",
        "            pretrained_dict = torch.load('./Pretrained/mit_b3.pth')\n",
        "        if self.model_type == 'MitB4':\n",
        "            pretrained_dict = torch.load('./Pretrained/mit_b4.pth')\n",
        "        if self.model_type == 'MitB5':\n",
        "            pretrained_dict = torch.load('./Pretrained/mit_b5.pth')\n",
        "            \n",
        "            \n",
        "        model_dict = self.backbone.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        self.backbone.load_state_dict(model_dict)\n",
        "        print(\"successfully loaded!!!!\")\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        ##################  Go through backbone ###################\n",
        "        \n",
        "        B = x.shape[0]\n",
        "        \n",
        "        #stage 1\n",
        "        out_1, H, W = self.backbone.patch_embed1(x)\n",
        "        for i, blk in enumerate(self.backbone.block1):\n",
        "            out_1 = blk(out_1, H, W)\n",
        "        out_1 = self.backbone.norm1(out_1)\n",
        "        out_1 = out_1.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()  #(Batch_Size, self.backbone.embed_dims[0], 88, 88)\n",
        "        \n",
        "        # stage 2\n",
        "        out_2, H, W = self.backbone.patch_embed2(out_1)\n",
        "        for i, blk in enumerate(self.backbone.block2):\n",
        "            out_2 = blk(out_2, H, W)\n",
        "        out_2 = self.backbone.norm2(out_2)\n",
        "        out_2 = out_2.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()  #(Batch_Size, self.backbone.embed_dims[1], 44, 44)\n",
        "        \n",
        "        # stage 3\n",
        "        out_3, H, W = self.backbone.patch_embed3(out_2)\n",
        "        for i, blk in enumerate(self.backbone.block3):\n",
        "            out_3 = blk(out_3, H, W)\n",
        "        out_3 = self.backbone.norm3(out_3)\n",
        "        out_3 = out_3.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()  #(Batch_Size, self.backbone.embed_dims[2], 22, 22)\n",
        "        \n",
        "        # stage 4\n",
        "        out_4, H, W = self.backbone.patch_embed4(out_3)\n",
        "        for i, blk in enumerate(self.backbone.block4):\n",
        "            out_4 = blk(out_4, H, W)\n",
        "        out_4 = self.backbone.norm4(out_4)\n",
        "        out_4 = out_4.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()  #(Batch_Size, self.backbone.embed_dims[3], 11, 11)\n",
        "        \n",
        "        return out_1, out_2, out_3, out_4\n",
        "    \n",
        "# model = Feature_extractor_MIT(model_type = \"MitB5\")\n",
        "# x = torch.rand(2,3,352,352)\n",
        "# outs = model(x)\n",
        "# channels = []\n",
        "# for out in outs:\n",
        "#     print(out.shape)\n",
        "#     channels.append(out.shape[1])\n",
        "# print(channels)"
      ],
      "metadata": {
        "id": "obL-69IW4vpJ",
        "papermill": {
          "duration": 0.14955,
          "end_time": "2022-12-21T01:12:15.532995",
          "exception": false,
          "start_time": "2022-12-21T01:12:15.383445",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:15.502909Z",
          "iopub.execute_input": "2023-01-18T12:52:15.503207Z",
          "iopub.status.idle": "2023-01-18T12:52:15.586949Z",
          "shell.execute_reply.started": "2023-01-18T12:52:15.503182Z",
          "shell.execute_reply": "2023-01-18T12:52:15.585914Z"
        },
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pvit"
      ],
      "metadata": {
        "id": "VYstq8pi6V1p",
        "papermill": {
          "duration": 0.059574,
          "end_time": "2022-12-21T01:12:15.651192",
          "exception": false,
          "start_time": "2022-12-21T01:12:15.591618",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Ported from https://github.com/whai362/PVT (unmodified)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "\n",
        "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
        "from timm.models.registry import register_model\n",
        "from timm.models.vision_transformer import _cfg\n",
        "import math\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0., linear=False):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.dwconv = DWConv(hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.linear = linear\n",
        "        if self.linear:\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        x = self.fc1(x)\n",
        "        if self.linear:\n",
        "            x = self.relu(x)\n",
        "        x = self.dwconv(x, H, W)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., sr_ratio=1, linear=False):\n",
        "        super().__init__()\n",
        "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
        "        self.kv = nn.Linear(dim, dim * 2, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        self.linear = linear\n",
        "        self.sr_ratio = sr_ratio\n",
        "        if not linear:\n",
        "            if sr_ratio > 1:\n",
        "                self.sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)\n",
        "                self.norm = nn.LayerNorm(dim)\n",
        "        else:\n",
        "            self.pool = nn.AdaptiveAvgPool2d(7)\n",
        "            self.sr = nn.Conv2d(dim, dim, kernel_size=1, stride=1)\n",
        "            self.norm = nn.LayerNorm(dim)\n",
        "            self.act = nn.GELU()\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, N, C = x.shape\n",
        "        q = self.q(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
        "\n",
        "        if not self.linear:\n",
        "            if self.sr_ratio > 1:\n",
        "                x_ = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "                x_ = self.sr(x_).reshape(B, C, -1).permute(0, 2, 1)\n",
        "                x_ = self.norm(x_)\n",
        "                kv = self.kv(x_).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "            else:\n",
        "                kv = self.kv(x).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        else:\n",
        "            x_ = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "            x_ = self.sr(self.pool(x_)).reshape(B, C, -1).permute(0, 2, 1)\n",
        "            x_ = self.norm(x_)\n",
        "            x_ = self.act(x_)\n",
        "            kv = self.kv(x_).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        k, v = kv[0], kv[1]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, sr_ratio=1, linear=False):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "            dim,\n",
        "            num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "            attn_drop=attn_drop, proj_drop=drop, sr_ratio=sr_ratio, linear=linear)\n",
        "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop, linear=linear)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x), H, W))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x), H, W))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class OverlapPatchEmbed(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=7, stride=4, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        \n",
        "        img_size = to_2tuple(img_size)\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        \n",
        "        assert max(patch_size) > stride, \"Set larger patch_size than stride\"\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.H, self.W = img_size[0] // stride, img_size[1] // stride\n",
        "        self.num_patches = self.H * self.W\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride,\n",
        "                              padding=(patch_size[0] // 2, patch_size[1] // 2))\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        _, _, H, W = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        return x, H, W\n",
        "\n",
        "\n",
        "class PyramidVisionTransformerV2(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dims=[64, 128, 256, 512],\n",
        "                 num_heads=[1, 2, 4, 8], mlp_ratios=[4, 4, 4, 4], qkv_bias=False, qk_scale=None, drop_rate=0.,\n",
        "                 attn_drop_rate=0., drop_path_rate=0., norm_layer=nn.LayerNorm,\n",
        "                 depths=[3, 4, 6, 3], sr_ratios=[8, 4, 2, 1], num_stages=4, linear=False):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.depths = depths\n",
        "        self.num_stages = num_stages\n",
        "\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
        "        cur = 0\n",
        "\n",
        "        for i in range(num_stages):\n",
        "            patch_embed = OverlapPatchEmbed(img_size=img_size if i == 0 else img_size // (2 ** (i + 1)),\n",
        "                                            patch_size=7 if i == 0 else 3,\n",
        "                                            stride=4 if i == 0 else 2,\n",
        "                                            in_chans=in_chans if i == 0 else embed_dims[i - 1],\n",
        "                                            embed_dim=embed_dims[i])\n",
        "\n",
        "            block = nn.ModuleList([Block(\n",
        "                dim=embed_dims[i], num_heads=num_heads[i], mlp_ratio=mlp_ratios[i], qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[cur + j], norm_layer=norm_layer,\n",
        "                sr_ratio=sr_ratios[i], linear=linear)\n",
        "                for j in range(depths[i])])\n",
        "            norm = norm_layer(embed_dims[i])\n",
        "            cur += depths[i]\n",
        "\n",
        "            setattr(self, f\"patch_embed{i + 1}\", patch_embed)\n",
        "            setattr(self, f\"block{i + 1}\", block)\n",
        "            setattr(self, f\"norm{i + 1}\", norm)\n",
        "\n",
        "        # classification head\n",
        "        self.head = nn.Linear(embed_dims[3], num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def freeze_patch_emb(self):\n",
        "        self.patch_embed1.requires_grad = False\n",
        "\n",
        "    @torch.jit.ignore\n",
        "    def no_weight_decay(self):\n",
        "        return {'pos_embed1', 'pos_embed2', 'pos_embed3', 'pos_embed4', 'cls_token'}  # has pos_embed may be better\n",
        "\n",
        "    def get_classifier(self):\n",
        "        return self.head\n",
        "\n",
        "    def reset_classifier(self, num_classes, global_pool=''):\n",
        "        self.num_classes = num_classes\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "        features_maps = []\n",
        "\n",
        "        for i in range(self.num_stages):\n",
        "            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n",
        "            block = getattr(self, f\"block{i + 1}\")\n",
        "            norm = getattr(self, f\"norm{i + 1}\")\n",
        "            x, H, W = patch_embed(x)\n",
        "            for blk in block:\n",
        "                x = blk(x, H, W)\n",
        "            x = norm(x)\n",
        "            features_maps.append(x.view(B, H, W, -1).permute(0, 3, 1, 2).contiguous())\n",
        "            if i != self.num_stages - 1:\n",
        "                x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
        "                # print(i, x.shape)\n",
        "\n",
        "        return features_maps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.forward_features(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DWConv(nn.Module):\n",
        "    def __init__(self, dim=768):\n",
        "        super(DWConv, self).__init__()\n",
        "        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, N, C = x.shape\n",
        "        x = x.transpose(1, 2).view(B, C, H, W)\n",
        "        x = self.dwconv(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def _conv_filter(state_dict, patch_size=16):\n",
        "    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n",
        "    out_dict = {}\n",
        "    for k, v in state_dict.items():\n",
        "        if 'patch_embed.proj.weight' in k:\n",
        "            v = v.reshape((v.shape[0], 3, patch_size, patch_size))\n",
        "        out_dict[k] = v\n",
        "\n",
        "    return out_dict\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b0(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[32, 64, 160, 256], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[2, 2, 2, 2], sr_ratios=[8, 4, 2, 1],\n",
        "        **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b1(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[2, 2, 2, 2], sr_ratios=[8, 4, 2, 1],\n",
        "        **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b2(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 4, 6, 3], sr_ratios=[8, 4, 2, 1], **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b3(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 4, 18, 3], sr_ratios=[8, 4, 2, 1],\n",
        "        **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b4(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 8, 27, 3], sr_ratios=[8, 4, 2, 1],\n",
        "        **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b5(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[4, 4, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 6, 40, 3], sr_ratios=[8, 4, 2, 1],\n",
        "        **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvt_v2_b2_li(pretrained=False, **kwargs):\n",
        "    model = PyramidVisionTransformerV2(\n",
        "        patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=True,\n",
        "        norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[3, 4, 6, 3], sr_ratios=[8, 4, 2, 1], linear=True, **kwargs)\n",
        "    model.default_cfg = _cfg()\n",
        "\n",
        "    return model\n",
        "\n",
        "class Feature_extractor_PVT(nn.Module):\n",
        "    def __init__(self, model_type=\"PvtB4\"):\n",
        "        super().__init__()\n",
        "        if model_type == 'PvtB0':\n",
        "            pretrained_dict = torch.load('./pvt_v2_b0.pth')\n",
        "            self.backbone = pvt_v2_b0()\n",
        "            self.backbone.load_state_dict(pretrained_dict)\n",
        "            print(\"Load checkpoint successfuly!!\")\n",
        "            self.channel = [32, 64, 160, 256]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if model_type == 'PvtB1':\n",
        "            pretrained_dict = torch.load('./pvt_v2_b1.pth')\n",
        "            self.backbone = pvt_v2_b1()\n",
        "            self.backbone.load_state_dict(pretrained_dict)\n",
        "            print(\"Load checkpoint successfuly!!\")\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if model_type == 'PvtB2':\n",
        "            pretrained_dict = torch.load('./pvt_v2_b2.pth')\n",
        "            self.backbone = pvt_v2_b2()\n",
        "            self.backbone.load_state_dict(pretrained_dict)\n",
        "            print(\"Load checkpoint successfuly!!\")\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if model_type == 'PvtB3':\n",
        "            pretrained_dict = torch.load('./pvt_v2_b3.pth')\n",
        "            self.backbone = pvt_v2_b3()\n",
        "            self.backbone.load_state_dict(pretrained_dict)\n",
        "            print(\"Load checkpoint successfuly!!\")\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "        if model_type == 'PvtB4':\n",
        "            pretrained_dict = torch.load('./pvt_v2_b4.pth')\n",
        "            self.backbone = pvt_v2_b4()\n",
        "            self.backbone.load_state_dict(pretrained_dict)\n",
        "            print(\"Load checkpoint successfuly!!\")\n",
        "            self.channel = [64, 128, 320, 512]\n",
        "            self.scale = [1/8, 1/4, 1/2, 1/1, 2, 4, 8]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        return features\n",
        "\n",
        "# x = torch.rand(2,3,224,224)\n",
        "# model = Feature_extractor_PVT()\n",
        "# out = model(x)\n",
        "# for item in out:\n",
        "#     print(item.shape)\n",
        "# # print(out.shape)"
      ],
      "metadata": {
        "id": "JshwNWTF6LXk",
        "papermill": {
          "duration": 4.648811,
          "end_time": "2022-12-21T01:12:20.359663",
          "exception": false,
          "start_time": "2022-12-21T01:12:15.710852",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:15.607484Z",
          "iopub.execute_input": "2023-01-18T12:52:15.607739Z",
          "iopub.status.idle": "2023-01-18T12:52:20.756454Z",
          "shell.execute_reply.started": "2023-01-18T12:52:15.607715Z",
          "shell.execute_reply": "2023-01-18T12:52:20.755378Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "JOfhbVKc4vpN",
        "papermill": {
          "duration": 0.061397,
          "end_time": "2022-12-21T01:12:20.483530",
          "exception": false,
          "start_time": "2022-12-21T01:12:20.422133",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module"
      ],
      "metadata": {
        "id": "SyUuvwASsYMl",
        "papermill": {
          "duration": 0.063994,
          "end_time": "2022-12-21T01:12:20.609612",
          "exception": false,
          "start_time": "2022-12-21T01:12:20.545618",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EFFat(nn.Module):\n",
        "\n",
        "    def __init__(self, channel=512,reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c) + self.max_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x) + x\n",
        "    \n",
        "\n",
        "class convMixerLayer(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size) -> None:\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels=in_channel, \n",
        "            out_channels=in_channel, \n",
        "            groups=in_channel, \n",
        "            kernel_size=kernel_size,\n",
        "            stride=1,\n",
        "            padding=\"same\"\n",
        "        )\n",
        "        self.eff = EFFat(out_channel)\n",
        "        self.pointwise = nn.Conv2d(in_channel, out_channel, 1, 1)\n",
        "        self.activation = nn.SiLU()\n",
        "        self.batchnorm1 = nn.BatchNorm2d(in_channel)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(out_channel)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ori = x\n",
        "        x = self.depthwise(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.eff(self.batchnorm1(x)) + ori\n",
        "        x = self.pointwise(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SEModule(nn.Module):\n",
        "    def __init__(self, channels, reduction):\n",
        "        super(SEModule, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(\n",
        "            channels, channels // reduction, kernel_size=1, padding=0 ,bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Conv2d(\n",
        "            channels // reduction, channels, kernel_size=1, padding=0 ,bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        module_input = x\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return module_input * x\n",
        "\n",
        "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n",
        "    # Pad to 'same' shape outputs\n",
        "    if d > 1:\n",
        "        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n",
        "    if p is None:\n",
        "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
        "    return p\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    # Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)\n",
        "    default_act = nn.SiLU()  # default activation\n",
        "\n",
        "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(c2)\n",
        "        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "    def forward_fuse(self, x):\n",
        "        return self.act(self.conv(x))\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Standard bottleneck\n",
        "    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n",
        "        super().__init__()\n",
        "        c_ = int(c2 * e)  # hidden channels\n",
        "        self.cv1 = Conv(c1, c_, 1, 1)\n",
        "        self.cv2 = Conv(c_, c2, 3, 1, g=g)\n",
        "        self.add = shortcut and c1 == c2\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
        "\n",
        "class BottleneckCSP(nn.Module):\n",
        "    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n",
        "    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n",
        "        super().__init__()\n",
        "        c_ = int(c2 * e)  # hidden channels\n",
        "        self.cv1 = Conv(c1, c_, 1, 1)\n",
        "        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)\n",
        "        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)\n",
        "        self.cv4 = Conv(2 * c_, c2, 1, 1)\n",
        "        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)\n",
        "        self.act = nn.SiLU()\n",
        "        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.cv3(self.m(self.cv1(x)))\n",
        "        y2 = self.cv2(x)\n",
        "        return self.cv4(self.act(self.bn(torch.cat((y1, y2), 1))))\n",
        "\n",
        "class Channel_attention(nn.Module):\n",
        "    def __init__(self, c, reduction=16) -> None:\n",
        "        super().__init__()\n",
        "        self.fcap1 = nn.Conv2d(c, c//reduction,1)\n",
        "        self.fcmp1 = nn.Conv2d(c, c//reduction, 1)\n",
        "        self.fcap2 = nn.Conv2d(c//reduction, c, 1)\n",
        "        self.fcmp2 = nn.Conv2d(c//reduction, c, 1)\n",
        "        self.acg = nn.Conv2d(c//reduction, c, 1)\n",
        "    def forward(self, x):\n",
        "        f1 = F.relu(self.fcap1(x))\n",
        "        f2 = F.relu(self.fcmp1(x))\n",
        "        f = self.acg(f1 + f2)\n",
        "        out = F.sigmoid(f + self.fcap2(f1) + self.fcmp2(f2))*x\n",
        "        return out\n",
        "\n",
        "class CTblock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size=3) -> None:\n",
        "        super().__init__()\n",
        "        self.mixspatial = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, in_channel, kernel_size, padding=\"same\", groups=in_channel),\n",
        "            nn.BatchNorm2d(in_channel),\n",
        "            nn.ReLU(),\n",
        "            Channel_attention(in_channel),\n",
        "            nn.Conv2d(in_channel, out_channel, 3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "        )\n",
        "        self.mixchannel = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, out_channel, 1, 1),\n",
        "            nn.BatchNorm2d(out_channel),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.mixspatial(x) + self.mixchannel(x))\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "d3XwCBoQk_Yt",
        "papermill": {
          "duration": 0.100802,
          "end_time": "2022-12-21T01:12:20.775004",
          "exception": false,
          "start_time": "2022-12-21T01:12:20.674202",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:20.760287Z",
          "iopub.execute_input": "2023-01-18T12:52:20.760581Z",
          "iopub.status.idle": "2023-01-18T12:52:20.794324Z",
          "shell.execute_reply.started": "2023-01-18T12:52:20.760554Z",
          "shell.execute_reply": "2023-01-18T12:52:20.793366Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTDCFormer"
      ],
      "metadata": {
        "id": "CMCWZ9pPsjlr",
        "papermill": {
          "duration": 0.062327,
          "end_time": "2022-12-21T01:12:20.900155",
          "exception": false,
          "start_time": "2022-12-21T01:12:20.837828",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UpDownstream(nn.Module):\n",
        "    def __init__(self, scale, in_channel, out_channel) -> None:\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.conv1x1 = nn.Conv2d(in_channel, out_channel, 1)\n",
        "        self.bn = nn.BatchNorm2d(out_channel)\n",
        "        self.ac = nn.GELU()\n",
        "    def forward(self, x):\n",
        "        x = self.conv1x1(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.ac(x)\n",
        "        bn, c, h, w = x.shape\n",
        "        x = F.interpolate(x, size=(int(h*self.scale), int(w*self.scale)), mode=\"bilinear\")\n",
        "        return x\n",
        "\n",
        "class NormMode(nn.Module):\n",
        "    def __init__(self, scale, in_channel, out_channel) -> None:\n",
        "        super().__init__()\n",
        "        \"\"\"nhận đầu vào là một tensor cxhxw\n",
        "\n",
        "        Returns:\n",
        "            - vector key: d\n",
        "            - Tensor value: c1xh1xw1\n",
        "        \"\"\"\n",
        "        self.norm = UpDownstream(scale, in_channel, out_channel)\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.mg = nn.AdaptiveMaxPool2d((1,1))\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Conv2d(in_channel, in_channel, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(in_channel, out_channel, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        v = self.norm(x).unsqueeze(1) # (bs, 1, c, h, w)\n",
        "        k = self.mlp(self.avg(x)+self.mg(x)).view(x.shape[0], 1, -1) #(bs,1, c)\n",
        "        return v, k\n",
        "        \n",
        "\n",
        "class AttentionDC(nn.Module):\n",
        "    def __init__(self, scale, in_channel, out_channel) -> None:\n",
        "        super().__init__()\n",
        "        self.normfm1 = NormMode(scale[0], in_channel[0], out_channel)\n",
        "        self.normfm2 = NormMode(scale[1], in_channel[1], out_channel)\n",
        "        self.normfm3 = NormMode(scale[2], in_channel[2], out_channel)\n",
        "        self.normfm4 = NormMode(scale[3], in_channel[3], out_channel)\n",
        "        self.normfmDecode = NormMode(1, out_channel, out_channel)\n",
        "        self.mlp = nn.Linear(out_channel*2, out_channel)\n",
        "\n",
        "    \n",
        "    def forward(self, feature_maps):\n",
        "        fm1, fm2, fm3, fm4, fmdecode = feature_maps\n",
        "        v1, k1 = self.normfm1(fm1)\n",
        "        v2, k2 = self.normfm2(fm2)\n",
        "        v3, k3 = self.normfm3(fm3)\n",
        "        v4, k4 = self.normfm4(fm4)\n",
        "        vd, qd = self.normfmDecode(fmdecode) #(bs, 1, c)\n",
        "        K = torch.cat([k1, k2, k3, k4], dim=1) #(bs, 4, c)\n",
        "        K = torch.cat([K, qd.expand_as(K)], dim=2) #(bs, 4, 2c)\n",
        "        atten = F.softmax(self.mlp(K), dim=1).unsqueeze(-1).unsqueeze(-1)   #(bs, 4, c, 1, 1)\n",
        "        V = torch.cat([v1,v2,v3,v4], dim=1) #(bs, 4, c, h, w)\n",
        "        V = V*atten #(bs, 4, c, h, w)\n",
        "        V = torch.sum(V, dim=1) #(bs, c, h, w)\n",
        "        V = torch.cat([V, vd.squeeze(1)], dim=1)\n",
        "        return V\n",
        "\n",
        "class RB(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, dilation=2, padding=\"same\"),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.out_layers = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=2, padding=\"same\"),\n",
        "            nn.BatchNorm2d(out_channels, out_channels),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        if out_channels == in_channels:\n",
        "            self.skip = nn.Identity()\n",
        "        else:\n",
        "            self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.in_layers(x)\n",
        "        h = self.out_layers(h)\n",
        "        return h + self.skip(x)\n",
        "\n",
        "        \n",
        "\n",
        "class CTDC(nn.Module):\n",
        "    def __init__(self, args = args) -> None:\n",
        "        super().__init__()\n",
        "        if \"Mit\" in args.backbone:\n",
        "            self.feature_extractor = Feature_extractor_MIT(args.backbone)\n",
        "            channel, scale = self.feature_extractor.channel, self.feature_extractor.scale\n",
        "        elif \"Pvt\" in args.backbone:\n",
        "            self.feature_extractor = Feature_extractor_PVT(args.backbone)\n",
        "            channel, scale = self.feature_extractor.channel, self.feature_extractor.scale\n",
        "        \n",
        "        self.attention1 = AttentionDC(scale[:4], channel, channel[-1])\n",
        "        self.attention2 = AttentionDC(scale[1:5], channel, channel[-2])\n",
        "        self.attention3 = AttentionDC(scale[2:6], channel, channel[-3])\n",
        "        self.attention4 = AttentionDC(scale[3:7], channel, channel[-4])\n",
        "        # self.csp = BottleneckCSP(channel[-1], channel[-1])\n",
        "        self.rb1 = nn.Sequential(\n",
        "            RB(channel[-1], channel[-1]),\n",
        "            RB(channel[-1], channel[-1])\n",
        "        )\n",
        "        self.rb2 = nn.Sequential(\n",
        "            RB(channel[-1]*2, channel[-2]),\n",
        "            RB(channel[-2], channel[-2]),\n",
        "        )\n",
        "        self.rb3 = nn.Sequential(\n",
        "            RB(channel[-2]*2, channel[-3]),\n",
        "            RB(channel[-3], channel[-3]),\n",
        "        )\n",
        "        self.rb4 = nn.Sequential(\n",
        "            RB(channel[-3]*2, channel[-4]),\n",
        "            RB(channel[-4], channel[-4]),\n",
        "        )\n",
        "        self.rb5 = nn.Sequential(\n",
        "            RB(channel[-4]*2, channel[-4]),\n",
        "            RB(channel[-4], channel[-4])\n",
        "        )\n",
        "        self.rb6 = nn.Sequential(\n",
        "            RB(channel[-4], channel[-4]),\n",
        "            RB(channel[-4], channel[-4]),\n",
        "        )\n",
        "        self.head = nn.Conv2d(channel[-4], 1, 1)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        fm1, fm2, fm3, fm4 = self.feature_extractor(x)\n",
        "        decode1 = self.rb1(fm4) #328x7x7\n",
        "        out1 = self.attention1([fm1, fm2, fm3, fm4, decode1]) #756x7x7\n",
        "        decode2 = F.interpolate(self.rb2(out1), (out1.shape[2]*2, out1.shape[3]*2), mode=\"bilinear\") #192x14x14\n",
        "        out2 = self.attention2([fm1, fm2, fm3, fm4, decode2]) #384x14x14\n",
        "        decode3 = F.interpolate(self.rb3(out2), (out2.shape[2]*2, out2.shape[3]*2), mode=\"bilinear\") #80x28x28\n",
        "        out3 = self.attention3([fm1, fm2, fm3, fm4, decode3]) #160x28x28\n",
        "        decode4 = F.interpolate(self.rb4(out3), (out3.shape[2]*2, out3.shape[3]*2), mode=\"bilinear\") #56x56x56\n",
        "        out4 = self.attention4([fm1, fm2, fm3, fm4, decode4]) #112x56x56\n",
        "        decode5 = F.interpolate(self.rb5(out4), (out4.shape[2]*2, out4.shape[3]*2), mode=\"bilinear\") #32x112x112\n",
        "        decode6 = F.interpolate(self.rb6(decode5), (decode5.shape[2]*2, decode5.shape[3]*2), mode=\"bilinear\")\n",
        "        mask_pred = self.head(decode6)\n",
        "        return mask_pred\n",
        "\n",
        "# model = CTDC()\n",
        "# x = torch.rand(2,3,352,352)\n",
        "# out = model(x)\n",
        "# print(out.shape)\n"
      ],
      "metadata": {
        "id": "vM_JjVEZ4vpN",
        "papermill": {
          "duration": 6.169207,
          "end_time": "2022-12-21T01:12:27.130656",
          "exception": false,
          "start_time": "2022-12-21T01:12:20.961449",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:20.798012Z",
          "iopub.execute_input": "2023-01-18T12:52:20.798495Z",
          "iopub.status.idle": "2023-01-18T12:52:26.447882Z",
          "shell.execute_reply.started": "2023-01-18T12:52:20.798467Z",
          "shell.execute_reply": "2023-01-18T12:52:26.446921Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unet3++"
      ],
      "metadata": {
        "id": "K76NE1DbJl-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import init\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def weights_init_xavier(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_normal_(m.weight.data, gain=1)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.xavier_normal_(m.weight.data, gain=1)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def weights_init_kaiming(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "def weights_init_orthogonal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.orthogonal_(m.weight.data, gain=1)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.orthogonal_(m.weight.data, gain=1)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "def init_weights(net, init_type='normal'):\n",
        "    if init_type == 'normal':\n",
        "        net.apply(weights_init_normal)\n",
        "    elif init_type == 'xavier':\n",
        "        net.apply(weights_init_xavier)\n",
        "    elif init_type == 'kaiming':\n",
        "        net.apply(weights_init_kaiming)\n",
        "    elif init_type == 'orthogonal':\n",
        "        net.apply(weights_init_orthogonal)\n",
        "    else:\n",
        "        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "\n",
        "class unetConv2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, is_batchnorm, n=2, ks=3, stride=1, padding=1):\n",
        "        super(unetConv2, self).__init__()\n",
        "        self.n = n\n",
        "        self.ks = ks\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        s = stride\n",
        "        p = padding\n",
        "        \n",
        "        if is_batchnorm:\n",
        "            for i in range(1, n + 1):\n",
        "                conv = nn.Sequential(nn.Conv2d(in_size, out_size, ks, s, p),\n",
        "                                     nn.BatchNorm2d(out_size), nn.ReLU(inplace=True),)\n",
        "                setattr(self, 'conv%d' % i, conv)\n",
        "                in_size = out_size\n",
        "        else:\n",
        "            for i in range(1, n + 1):\n",
        "                conv = nn.Sequential(nn.Conv2d(in_size, out_size, ks, s, p), nn.ReLU(inplace=True), )\n",
        "                setattr(self, 'conv%d' % i, conv)\n",
        "                in_size = out_size\n",
        "\n",
        "        # initialise the blocks\n",
        "        for m in self.children():\n",
        "            init_weights(m, init_type='kaiming')\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        for i in range(1, self.n + 1):\n",
        "            conv = getattr(self, 'conv%d' % i)\n",
        "            x = conv(x)\n",
        "        return x\n",
        "\n",
        "class UNet3Plus(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1, bilinear=True, feature_scale=4,\n",
        "                 is_deconv=True, is_batchnorm=True):\n",
        "        super(UNet3Plus, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "        self.feature_scale = feature_scale\n",
        "        self.is_deconv = is_deconv\n",
        "        self.is_batchnorm = is_batchnorm\n",
        "        filters = [64, 128, 256, 512, 1024]\n",
        "\n",
        "        ## -------------Encoder--------------\n",
        "        self.conv1 = unetConv2(self.n_channels, filters[0], self.is_batchnorm)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2 = unetConv2(filters[0], filters[1], self.is_batchnorm)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = unetConv2(filters[1], filters[2], self.is_batchnorm)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv4 = unetConv2(filters[2], filters[3], self.is_batchnorm)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv5 = unetConv2(filters[3], filters[4], self.is_batchnorm)\n",
        "\n",
        "        ## -------------Decoder--------------\n",
        "        self.CatChannels = filters[0]\n",
        "        self.CatBlocks = 5\n",
        "        self.UpChannels = self.CatChannels * self.CatBlocks\n",
        "\n",
        "        '''stage 4d'''\n",
        "        # h1->320*320, hd4->40*40, Pooling 8 times\n",
        "        self.h1_PT_hd4 = nn.MaxPool2d(8, 8, ceil_mode=True)\n",
        "        self.h1_PT_hd4_conv = nn.Conv2d(filters[0], self.CatChannels, 3, padding=1)\n",
        "        self.h1_PT_hd4_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h1_PT_hd4_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # h2->160*160, hd4->40*40, Pooling 4 times\n",
        "        self.h2_PT_hd4 = nn.MaxPool2d(4, 4, ceil_mode=True)\n",
        "        self.h2_PT_hd4_conv = nn.Conv2d(filters[1], self.CatChannels, 3, padding=1)\n",
        "        self.h2_PT_hd4_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h2_PT_hd4_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # h3->80*80, hd4->40*40, Pooling 2 times\n",
        "        self.h3_PT_hd4 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        self.h3_PT_hd4_conv = nn.Conv2d(filters[2], self.CatChannels, 3, padding=1)\n",
        "        self.h3_PT_hd4_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h3_PT_hd4_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # h4->40*40, hd4->40*40, Concatenation\n",
        "        self.h4_Cat_hd4_conv = nn.Conv2d(filters[3], self.CatChannels, 3, padding=1)\n",
        "        self.h4_Cat_hd4_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h4_Cat_hd4_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd5->20*20, hd4->40*40, Upsample 2 times\n",
        "        self.hd5_UT_hd4 = nn.Upsample(scale_factor=2, mode='bilinear')  # 14*14\n",
        "        self.hd5_UT_hd4_conv = nn.Conv2d(filters[4], self.CatChannels, 3, padding=1)\n",
        "        self.hd5_UT_hd4_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd5_UT_hd4_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # fusion(h1_PT_hd4, h2_PT_hd4, h3_PT_hd4, h4_Cat_hd4, hd5_UT_hd4)\n",
        "        self.conv4d_1 = nn.Conv2d(self.UpChannels, self.UpChannels, 3, padding=1)  # 16\n",
        "        self.bn4d_1 = nn.BatchNorm2d(self.UpChannels)\n",
        "        self.relu4d_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        '''stage 3d'''\n",
        "        # h1->320*320, hd3->80*80, Pooling 4 times\n",
        "        self.h1_PT_hd3 = nn.MaxPool2d(4, 4, ceil_mode=True)\n",
        "        self.h1_PT_hd3_conv = nn.Conv2d(filters[0], self.CatChannels, 3, padding=1)\n",
        "        self.h1_PT_hd3_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h1_PT_hd3_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # h2->160*160, hd3->80*80, Pooling 2 times\n",
        "        self.h2_PT_hd3 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        self.h2_PT_hd3_conv = nn.Conv2d(filters[1], self.CatChannels, 3, padding=1)\n",
        "        self.h2_PT_hd3_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h2_PT_hd3_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # h3->80*80, hd3->80*80, Concatenation\n",
        "        self.h3_Cat_hd3_conv = nn.Conv2d(filters[2], self.CatChannels, 3, padding=1)\n",
        "        self.h3_Cat_hd3_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h3_Cat_hd3_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd4->40*40, hd4->80*80, Upsample 2 times\n",
        "        self.hd4_UT_hd3 = nn.Upsample(scale_factor=2, mode='bilinear')  # 14*14\n",
        "        self.hd4_UT_hd3_conv = nn.Conv2d(self.UpChannels, self.CatChannels, 3, padding=1)\n",
        "        self.hd4_UT_hd3_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd4_UT_hd3_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd5->20*20, hd4->80*80, Upsample 4 times\n",
        "        self.hd5_UT_hd3 = nn.Upsample(scale_factor=4, mode='bilinear')  # 14*14\n",
        "        self.hd5_UT_hd3_conv = nn.Conv2d(filters[4], self.CatChannels, 3, padding=1)\n",
        "        self.hd5_UT_hd3_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd5_UT_hd3_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # fusion(h1_PT_hd3, h2_PT_hd3, h3_Cat_hd3, hd4_UT_hd3, hd5_UT_hd3)\n",
        "        self.conv3d_1 = nn.Conv2d(self.UpChannels, self.UpChannels, 3, padding=1)  # 16\n",
        "        self.bn3d_1 = nn.BatchNorm2d(self.UpChannels)\n",
        "        self.relu3d_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        '''stage 2d '''\n",
        "        # h1->320*320, hd2->160*160, Pooling 2 times\n",
        "        self.h1_PT_hd2 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        self.h1_PT_hd2_conv = nn.Conv2d(filters[0], self.CatChannels, 3, padding=1)\n",
        "        self.h1_PT_hd2_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h1_PT_hd2_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # h2->160*160, hd2->160*160, Concatenation\n",
        "        self.h2_Cat_hd2_conv = nn.Conv2d(filters[1], self.CatChannels, 3, padding=1)\n",
        "        self.h2_Cat_hd2_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h2_Cat_hd2_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd3->80*80, hd2->160*160, Upsample 2 times\n",
        "        self.hd3_UT_hd2 = nn.Upsample(scale_factor=2, mode='bilinear')  # 14*14\n",
        "        self.hd3_UT_hd2_conv = nn.Conv2d(self.UpChannels, self.CatChannels, 3, padding=1)\n",
        "        self.hd3_UT_hd2_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd3_UT_hd2_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd4->40*40, hd2->160*160, Upsample 4 times\n",
        "        self.hd4_UT_hd2 = nn.Upsample(scale_factor=4, mode='bilinear')  # 14*14\n",
        "        self.hd4_UT_hd2_conv = nn.Conv2d(self.UpChannels, self.CatChannels, 3, padding=1)\n",
        "        self.hd4_UT_hd2_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd4_UT_hd2_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd5->20*20, hd2->160*160, Upsample 8 times\n",
        "        self.hd5_UT_hd2 = nn.Upsample(scale_factor=8, mode='bilinear')  # 14*14\n",
        "        self.hd5_UT_hd2_conv = nn.Conv2d(filters[4], self.CatChannels, 3, padding=1)\n",
        "        self.hd5_UT_hd2_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd5_UT_hd2_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # fusion(h1_PT_hd2, h2_Cat_hd2, hd3_UT_hd2, hd4_UT_hd2, hd5_UT_hd2)\n",
        "        self.conv2d_1 = nn.Conv2d(self.UpChannels, self.UpChannels, 3, padding=1)  # 16\n",
        "        self.bn2d_1 = nn.BatchNorm2d(self.UpChannels)\n",
        "        self.relu2d_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        '''stage 1d'''\n",
        "        # h1->320*320, hd1->320*320, Concatenation\n",
        "        self.h1_Cat_hd1_conv = nn.Conv2d(filters[0], self.CatChannels, 3, padding=1)\n",
        "        self.h1_Cat_hd1_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.h1_Cat_hd1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd2->160*160, hd1->320*320, Upsample 2 times\n",
        "        self.hd2_UT_hd1 = nn.Upsample(scale_factor=2, mode='bilinear')  # 14*14\n",
        "        self.hd2_UT_hd1_conv = nn.Conv2d(self.UpChannels, self.CatChannels, 3, padding=1)\n",
        "        self.hd2_UT_hd1_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd2_UT_hd1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd3->80*80, hd1->320*320, Upsample 4 times\n",
        "        self.hd3_UT_hd1 = nn.Upsample(scale_factor=4, mode='bilinear')  # 14*14\n",
        "        self.hd3_UT_hd1_conv = nn.Conv2d(self.UpChannels, self.CatChannels, 3, padding=1)\n",
        "        self.hd3_UT_hd1_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd3_UT_hd1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd4->40*40, hd1->320*320, Upsample 8 times\n",
        "        self.hd4_UT_hd1 = nn.Upsample(scale_factor=8, mode='bilinear')  # 14*14\n",
        "        self.hd4_UT_hd1_conv = nn.Conv2d(self.UpChannels, self.CatChannels, 3, padding=1)\n",
        "        self.hd4_UT_hd1_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd4_UT_hd1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # hd5->20*20, hd1->320*320, Upsample 16 times\n",
        "        self.hd5_UT_hd1 = nn.Upsample(scale_factor=16, mode='bilinear')  # 14*14\n",
        "        self.hd5_UT_hd1_conv = nn.Conv2d(filters[4], self.CatChannels, 3, padding=1)\n",
        "        self.hd5_UT_hd1_bn = nn.BatchNorm2d(self.CatChannels)\n",
        "        self.hd5_UT_hd1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # fusion(h1_Cat_hd1, hd2_UT_hd1, hd3_UT_hd1, hd4_UT_hd1, hd5_UT_hd1)\n",
        "        self.conv1d_1 = nn.Conv2d(self.UpChannels, self.UpChannels, 3, padding=1)  # 16\n",
        "        self.bn1d_1 = nn.BatchNorm2d(self.UpChannels)\n",
        "        self.relu1d_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # output\n",
        "        self.outconv1 = nn.Conv2d(self.UpChannels, n_classes, 3, padding=1)\n",
        "\n",
        "        # initialise weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init_weights(m, init_type='kaiming')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init_weights(m, init_type='kaiming')\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        ## -------------Encoder-------------\n",
        "        h1 = self.conv1(inputs)  # h1->320*320*64\n",
        "\n",
        "        h2 = self.maxpool1(h1)\n",
        "        h2 = self.conv2(h2)  # h2->160*160*128\n",
        "\n",
        "        h3 = self.maxpool2(h2)\n",
        "        h3 = self.conv3(h3)  # h3->80*80*256\n",
        "\n",
        "        h4 = self.maxpool3(h3)\n",
        "        h4 = self.conv4(h4)  # h4->40*40*512\n",
        "\n",
        "        h5 = self.maxpool4(h4)\n",
        "        hd5 = self.conv5(h5)  # h5->20*20*1024\n",
        "\n",
        "        ## -------------Decoder-------------\n",
        "        h1_PT_hd4 = self.h1_PT_hd4_relu(self.h1_PT_hd4_bn(self.h1_PT_hd4_conv(self.h1_PT_hd4(h1))))\n",
        "        h2_PT_hd4 = self.h2_PT_hd4_relu(self.h2_PT_hd4_bn(self.h2_PT_hd4_conv(self.h2_PT_hd4(h2))))\n",
        "        h3_PT_hd4 = self.h3_PT_hd4_relu(self.h3_PT_hd4_bn(self.h3_PT_hd4_conv(self.h3_PT_hd4(h3))))\n",
        "        h4_Cat_hd4 = self.h4_Cat_hd4_relu(self.h4_Cat_hd4_bn(self.h4_Cat_hd4_conv(h4)))\n",
        "        hd5_UT_hd4 = self.hd5_UT_hd4_relu(self.hd5_UT_hd4_bn(self.hd5_UT_hd4_conv(self.hd5_UT_hd4(hd5))))\n",
        "        hd4 = self.relu4d_1(self.bn4d_1(self.conv4d_1(torch.cat((h1_PT_hd4, h2_PT_hd4, h3_PT_hd4, h4_Cat_hd4, hd5_UT_hd4), 1)))) # hd4->40*40*UpChannels\n",
        "\n",
        "        h1_PT_hd3 = self.h1_PT_hd3_relu(self.h1_PT_hd3_bn(self.h1_PT_hd3_conv(self.h1_PT_hd3(h1))))\n",
        "        h2_PT_hd3 = self.h2_PT_hd3_relu(self.h2_PT_hd3_bn(self.h2_PT_hd3_conv(self.h2_PT_hd3(h2))))\n",
        "        h3_Cat_hd3 = self.h3_Cat_hd3_relu(self.h3_Cat_hd3_bn(self.h3_Cat_hd3_conv(h3)))\n",
        "        hd4_UT_hd3 = self.hd4_UT_hd3_relu(self.hd4_UT_hd3_bn(self.hd4_UT_hd3_conv(self.hd4_UT_hd3(hd4))))\n",
        "        hd5_UT_hd3 = self.hd5_UT_hd3_relu(self.hd5_UT_hd3_bn(self.hd5_UT_hd3_conv(self.hd5_UT_hd3(hd5))))\n",
        "        hd3 = self.relu3d_1(self.bn3d_1(self.conv3d_1(torch.cat((h1_PT_hd3, h2_PT_hd3, h3_Cat_hd3, hd4_UT_hd3, hd5_UT_hd3), 1)))) # hd3->80*80*UpChannels\n",
        "\n",
        "        h1_PT_hd2 = self.h1_PT_hd2_relu(self.h1_PT_hd2_bn(self.h1_PT_hd2_conv(self.h1_PT_hd2(h1))))\n",
        "        h2_Cat_hd2 = self.h2_Cat_hd2_relu(self.h2_Cat_hd2_bn(self.h2_Cat_hd2_conv(h2)))\n",
        "        hd3_UT_hd2 = self.hd3_UT_hd2_relu(self.hd3_UT_hd2_bn(self.hd3_UT_hd2_conv(self.hd3_UT_hd2(hd3))))\n",
        "        hd4_UT_hd2 = self.hd4_UT_hd2_relu(self.hd4_UT_hd2_bn(self.hd4_UT_hd2_conv(self.hd4_UT_hd2(hd4))))\n",
        "        hd5_UT_hd2 = self.hd5_UT_hd2_relu(self.hd5_UT_hd2_bn(self.hd5_UT_hd2_conv(self.hd5_UT_hd2(hd5))))\n",
        "        hd2 = self.relu2d_1(self.bn2d_1(self.conv2d_1(torch.cat((h1_PT_hd2, h2_Cat_hd2, hd3_UT_hd2, hd4_UT_hd2, hd5_UT_hd2), 1)))) # hd2->160*160*UpChannels\n",
        "\n",
        "        h1_Cat_hd1 = self.h1_Cat_hd1_relu(self.h1_Cat_hd1_bn(self.h1_Cat_hd1_conv(h1)))\n",
        "        hd2_UT_hd1 = self.hd2_UT_hd1_relu(self.hd2_UT_hd1_bn(self.hd2_UT_hd1_conv(self.hd2_UT_hd1(hd2))))\n",
        "        hd3_UT_hd1 = self.hd3_UT_hd1_relu(self.hd3_UT_hd1_bn(self.hd3_UT_hd1_conv(self.hd3_UT_hd1(hd3))))\n",
        "        hd4_UT_hd1 = self.hd4_UT_hd1_relu(self.hd4_UT_hd1_bn(self.hd4_UT_hd1_conv(self.hd4_UT_hd1(hd4))))\n",
        "        hd5_UT_hd1 = self.hd5_UT_hd1_relu(self.hd5_UT_hd1_bn(self.hd5_UT_hd1_conv(self.hd5_UT_hd1(hd5))))\n",
        "        hd1 = self.relu1d_1(self.bn1d_1(self.conv1d_1(torch.cat((h1_Cat_hd1, hd2_UT_hd1, hd3_UT_hd1, hd4_UT_hd1, hd5_UT_hd1), 1)))) # hd1->320*320*UpChannels\n",
        "\n",
        "        d1 = self.outconv1(hd1)  # d1->320*320*n_classes\n",
        "        return d1\n",
        "\n",
        "# unetv3 = UNet3Plus()\n",
        "# x = torch.rand(2,3,320,320)\n",
        "# out = unetv3(x)"
      ],
      "metadata": {
        "id": "RAF4OgAIJlRY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loss"
      ],
      "metadata": {
        "id": "G_wL9JqC4vpY",
        "papermill": {
          "duration": 0.064284,
          "end_time": "2022-12-21T01:12:27.260520",
          "exception": false,
          "start_time": "2022-12-21T01:12:27.196236",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DiceLoss"
      ],
      "metadata": {
        "id": "BTOvVwldocvq",
        "papermill": {
          "duration": 0.061753,
          "end_time": "2022-12-21T01:12:27.385299",
          "exception": false,
          "start_time": "2022-12-21T01:12:27.323546",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        num = targets.size(0)\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        m1 = probs.view(num, -1)\n",
        "        m2 = targets.view(num, -1)\n",
        "        intersection = m1 * m2\n",
        "\n",
        "        score = (\n",
        "            2.0\n",
        "            * (intersection.sum(1) + self.smooth)\n",
        "            / (m1.sum(1) + m2.sum(1) + self.smooth)\n",
        "        )\n",
        "        score = 1 - score.sum() / num\n",
        "        return score\n"
      ],
      "metadata": {
        "id": "hpvkOGgI4vpY",
        "papermill": {
          "duration": 0.072665,
          "end_time": "2022-12-21T01:12:27.518753",
          "exception": false,
          "start_time": "2022-12-21T01:12:27.446088",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:26.450424Z",
          "iopub.execute_input": "2023-01-18T12:52:26.450892Z",
          "iopub.status.idle": "2023-01-18T12:52:26.457971Z",
          "shell.execute_reply.started": "2023-01-18T12:52:26.450854Z",
          "shell.execute_reply": "2023-01-18T12:52:26.456934Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FocalLoss"
      ],
      "metadata": {
        "id": "p2tfW_liogKr",
        "papermill": {
          "duration": 0.061463,
          "end_time": "2022-12-21T01:12:27.640549",
          "exception": false,
          "start_time": "2022-12-21T01:12:27.579086",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha,(float,int,long)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
        "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim()>2:\n",
        "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1,1)\n",
        "\n",
        "        logpt = F.log_softmax(input)\n",
        "        logpt = logpt.gather(1,target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = Variable(logpt.data.exp())\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type()!=input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0,target.data.view(-1))\n",
        "            logpt = logpt * Variable(at)\n",
        "\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\n",
        "        if self.size_average: return loss.mean()\n",
        "        else: return loss.sum()"
      ],
      "metadata": {
        "id": "OOKtqLSCoiz6",
        "papermill": {
          "duration": 0.07768,
          "end_time": "2022-12-21T01:12:27.780447",
          "exception": false,
          "start_time": "2022-12-21T01:12:27.702767",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:26.459674Z",
          "iopub.execute_input": "2023-01-18T12:52:26.460498Z",
          "iopub.status.idle": "2023-01-18T12:52:26.473140Z",
          "shell.execute_reply.started": "2023-01-18T12:52:26.460452Z",
          "shell.execute_reply": "2023-01-18T12:52:26.472151Z"
        },
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tversky-Kahneman"
      ],
      "metadata": {
        "id": "cOYxiY2LomXm",
        "papermill": {
          "duration": 0.062357,
          "end_time": "2022-12-21T01:12:27.965242",
          "exception": false,
          "start_time": "2022-12-21T01:12:27.902885",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://kornia.readthedocs.io/en/v0.1.2/losses.html"
      ],
      "metadata": {
        "id": "unWsAcGlok7g",
        "papermill": {
          "duration": 0.071545,
          "end_time": "2022-12-21T01:12:28.100423",
          "exception": false,
          "start_time": "2022-12-21T01:12:28.028878",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:26.474434Z",
          "iopub.execute_input": "2023-01-18T12:52:26.474931Z",
          "iopub.status.idle": "2023-01-18T12:52:26.483859Z",
          "shell.execute_reply.started": "2023-01-18T12:52:26.474893Z",
          "shell.execute_reply": "2023-01-18T12:52:26.482926Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "Sw-r3tgnoX2L",
        "papermill": {
          "duration": 0.062321,
          "end_time": "2022-12-21T01:12:28.228522",
          "exception": false,
          "start_time": "2022-12-21T01:12:28.166201",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceScore(torch.nn.Module):\n",
        "    def __init__(self, smooth=1):\n",
        "        super(DiceScore, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets, sigmoid=True):\n",
        "        num = targets.size(0)\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        m1 = probs.view(num, -1) > 0.5\n",
        "        m2 = targets.view(num, -1) > 0.5\n",
        "        intersection = m1 * m2\n",
        "\n",
        "        score = (\n",
        "            2.0\n",
        "            * (intersection.sum(1) + self.smooth)\n",
        "            / (m1.sum(1) + m2.sum(1) + self.smooth)\n",
        "        )\n",
        "        score = score.sum() / num\n",
        "        return score\n"
      ],
      "metadata": {
        "id": "IzGKlHXL4vpZ",
        "papermill": {
          "duration": 0.07266,
          "end_time": "2022-12-21T01:12:28.365844",
          "exception": false,
          "start_time": "2022-12-21T01:12:28.293184",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:26.485261Z",
          "iopub.execute_input": "2023-01-18T12:52:26.485777Z",
          "iopub.status.idle": "2023-01-18T12:52:26.495576Z",
          "shell.execute_reply.started": "2023-01-18T12:52:26.485741Z",
          "shell.execute_reply": "2023-01-18T12:52:26.494646Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config train"
      ],
      "metadata": {
        "id": "0YslUp5c4vpZ",
        "papermill": {
          "duration": 0.061297,
          "end_time": "2022-12-21T01:12:28.488924",
          "exception": false,
          "start_time": "2022-12-21T01:12:28.427627",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build"
      ],
      "metadata": {
        "id": "SZWpgtT3c-px",
        "papermill": {
          "duration": 0.062646,
          "end_time": "2022-12-21T01:12:28.613021",
          "exception": false,
          "start_time": "2022-12-21T01:12:28.550375",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build(args):\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "    root_train = args.root + \"/TrainDataset\"\n",
        "    root_test = args.root + \"/TestDataset\"\n",
        "    train_dataloader, test_dataloader = get_dataloaders(\n",
        "        root_train,\n",
        "        root_test,\n",
        "        batch_size=args.batch_size\n",
        "    )\n",
        "\n",
        "    Dice_loss = SoftDiceLoss()\n",
        "    BCE_loss = nn.BCELoss()\n",
        "    TverskyLoss = tgm.losses.TverskyLoss(alpha=0.5, beta=0.5)\n",
        "    FocalLoss = tgm.losses.FocalLoss(alpha=0.5, gamma=1, reduction='mean')\n",
        "    Ssim = tgm.losses.SSIM(5, reduction='none')\n",
        "    Smooth = tgm.losses.InverseDepthSmoothnessLoss()\n",
        "    loss_fun = {'Dice_loss':Dice_loss, \"BCE_loss\":BCE_loss, \"TverskyLoss\":TverskyLoss, \"FocalLoss\":FocalLoss,\\\n",
        "                \"Ssim\":Ssim, \"Smooth\":Smooth}\n",
        "\n",
        "    perf = DiceScore()\n",
        "\n",
        "    model = UNet3Plus()\n",
        "    if args.mgpu == \"true\":\n",
        "        model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "    #===================== Optimizer ===================================================\n",
        "    if args.optim == \"AdamW\":\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"SGD\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
        "    elif args.optim == \"Adadelta\":\n",
        "        optimizer = torch.optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"Adagrad\":\n",
        "        optimizer = torch.optim.Adagrad(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"Adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"SparseAdam\":\n",
        "        optimizer = torch.optim.SparseAdam(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"Adamax\":\n",
        "        optimizer = torch.optim.Adamax(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"ASGD\":\n",
        "        optimizer = torch.optim.Adamax(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"LBFGS\":\n",
        "        optimizer = torch.optim.LBFGS(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"NAdam\":\n",
        "        optimizer = torch.optim.NAdam(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"RAdam\":\n",
        "        optimizer = torch.optim.RAdam(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"RMSprop\":\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=args.lr)\n",
        "    elif args.optim == \"Rprop\":\n",
        "        optimizer = torch.optim.Rprop(model.parameters(), lr=args.lr)\n",
        "    #===================================================================================\n",
        "\n",
        "    if args.lrs == \"true\":\n",
        "        if args.type_lr == \"LROnP\":\n",
        "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                  optimizer, mode=\"max\", patience=10, factor=0.5, min_lr=args.lrs_min, verbose=True)\n",
        "        elif args.type_lr == \"StepLR\":\n",
        "            print(\"Using StepLR\")\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "                  optimizer, step_size=20, gamma=0.4, verbose=False)\n",
        "        elif args.type_lr == \"MultiStepLR\":\n",
        "            print(\"Using MultiStepLR\")\n",
        "            scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "                  optimizer, milestones=[10, 20, 30, 60], gamma=0.5, verbose=False)\n",
        "\n",
        "        \n",
        "    if args.checkpoint_path == None:\n",
        "        checkpoint = {\"test_measure_mean\":None, \"epoch\":0}\n",
        "    else:\n",
        "        checkpoint = torch.load(args.checkpoint_path)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer = torch.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "    return (device, train_dataloader, test_dataloader, Dice_loss,\n",
        "        BCE_loss, perf, model, optimizer, checkpoint, scheduler, loss_fun)\n",
        "\n",
        "( device, train_dataloader, test_dataloader, Dice_loss,\n",
        "BCE_loss, perf, model, optimizer, checkpoint, scheduler, loss_fun) = build(args)"
      ],
      "metadata": {
        "id": "LPQ7Wxukc9xZ",
        "outputId": "e682a22c-1d9b-4d45-c5e2-eb3394ee4a5c",
        "papermill": {
          "duration": 5.929461,
          "end_time": "2022-12-21T01:12:34.605003",
          "exception": false,
          "start_time": "2022-12-21T01:12:28.675542",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:26.498652Z",
          "iopub.execute_input": "2023-01-18T12:52:26.498903Z",
          "iopub.status.idle": "2023-01-18T12:52:33.107545Z",
          "shell.execute_reply.started": "2023-01-18T12:52:26.498879Z",
          "shell.execute_reply": "2023-01-18T12:52:33.106060Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using StepLR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader"
      ],
      "metadata": {
        "id": "skWEvnOdcdgP",
        "outputId": "2accdaca-43d6-4ca0-83ba-4b06579e2583",
        "papermill": {
          "duration": 0.073559,
          "end_time": "2022-12-21T01:12:34.741570",
          "exception": false,
          "start_time": "2022-12-21T01:12:34.668011",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:33.112649Z",
          "iopub.execute_input": "2023-01-18T12:52:33.115470Z",
          "iopub.status.idle": "2023-01-18T12:52:33.127734Z",
          "shell.execute_reply.started": "2023-01-18T12:52:33.115427Z",
          "shell.execute_reply": "2023-01-18T12:52:33.126637Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Kvasir': <torch.utils.data.dataloader.DataLoader at 0x7fa28139e850>,\n",
              " 'ETIS-LaribPolypDB': <torch.utils.data.dataloader.DataLoader at 0x7fa28139e640>,\n",
              " 'CVC-ColonDB': <torch.utils.data.dataloader.DataLoader at 0x7fa279052400>,\n",
              " 'CVC-ClinicDB': <torch.utils.data.dataloader.DataLoader at 0x7fa28139efa0>,\n",
              " 'CVC-300': <torch.utils.data.dataloader.DataLoader at 0x7fa279052340>}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "zMi6RoHT_SV7",
        "papermill": {
          "duration": 0.070192,
          "end_time": "2022-12-21T01:12:34.876565",
          "exception": false,
          "start_time": "2022-12-21T01:12:34.806373",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:33.135028Z",
          "iopub.execute_input": "2023-01-18T12:52:33.137290Z",
          "iopub.status.idle": "2023-01-18T12:52:33.143318Z",
          "shell.execute_reply.started": "2023-01-18T12:52:33.137254Z",
          "shell.execute_reply": "2023-01-18T12:52:33.142326Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, device, train_loader, optimizer, epoch, Dice_loss, BCE_loss):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    loss_accumulator = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        for k in range(0, data.shape[0], 4):\n",
        "            data_input = data[k:k + 4]\n",
        "            target_input = target[k:k+4]\n",
        "            output = model(data_input)\n",
        "            loss = Dice_loss(output, target_input) + BCE_loss(torch.sigmoid(output), target_input)\n",
        "            loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_accumulator.append(loss.item())\n",
        "        if batch_idx + 1 < len(train_loader):\n",
        "            print(\n",
        "                \"\\rTrain Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\\tTime: {:.6f}\".format(\n",
        "                    epoch, (batch_idx + 1) * len(data), len(train_loader.dataset), 100.0 * (batch_idx + 1) / len(train_loader),\n",
        "                    loss.item(), time.time() - t, ), end=\"\", )\n",
        "        else:\n",
        "            print(\n",
        "                \"\\rTrain Epoch: {} [{}/{} ({:.1f}%)]\\tAverage loss: {:.6f}\\tTime: {:.6f}\".format(\n",
        "                    epoch, (batch_idx + 1) * len(data), len(train_loader.dataset), 100.0 * (batch_idx + 1) / len(train_loader),\n",
        "                    np.mean(loss_accumulator), time.time() - t, ) )\n",
        "\n",
        "    return np.mean(loss_accumulator)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, device, test_loader, epoch, perf_measure, phase, verbose=True):\n",
        "    t = time.time()\n",
        "    model.eval()\n",
        "    perf_accumulator = []\n",
        "    mIOU = []\n",
        "    Dice = []\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        perf_accumulator.append(perf_measure(output, target).item())\n",
        "        mIOU.append(Fmstric.binary_jaccard_index(torch.sigmoid(output), target>0.5).item())\n",
        "        Dice.append(torchmetrics.functional.dice(torch.sigmoid(output), target>0.5).item())\n",
        "        if verbose:\n",
        "            if batch_idx + 1 < len(test_loader):\n",
        "                print(\n",
        "                    \"\\r{}  Epoch: {} [{}/{} ({:.1f}%)]\\tDice: {:.6f}\\tmIOU: {:.6f}\\tDice: {:.6f}\\tTime: {:.6f}\".format(\n",
        "                        phase, epoch, batch_idx + 1, len(test_loader), 100.0 * (batch_idx + 1) / len(test_loader),\n",
        "                        np.mean(perf_accumulator), np.mean(mIOU), np.mean(Dice), time.time() - t, ), end=\"\", )\n",
        "            else:\n",
        "                print(\n",
        "                    \"\\r{}  Epoch: {} [{}/{} ({:.1f}%)]\\tDice: {:.6f}\\tmIOU: {:.6f}\\tDice: {:.6f}\\tTime: {:.6f}\".format(\n",
        "                        phase,epoch, batch_idx + 1, len(test_loader), 100.0 * (batch_idx + 1) / len(test_loader),\n",
        "                        np.mean(perf_accumulator), np.mean(mIOU), np.mean(Dice), time.time() - t, ))\n",
        "\n",
        "    return np.mean(perf_accumulator), np.std(perf_accumulator), np.mean(mIOU)\n",
        "\n",
        "\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    if not os.path.exists(\"./Trained models\"):\n",
        "        os.makedirs(\"./Trained models\")\n",
        "\n",
        "    prev_best_test = checkpoint[\"test_measure_mean\"]\n",
        "    test_measure_mean, test_measure_std = 0, 0\n",
        "    print(\"best test:\", prev_best_test, \"epoch:\", checkpoint[\"epoch\"])\n",
        "    \n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        Dices = [\"Dice\"]\n",
        "        mIOUs = [\"mIOU\"]\n",
        "        try:\n",
        "            loss = train_epoch(\n",
        "                model, device, train_dataloader, optimizer, epoch, loss_fun[\"Dice_loss\"], loss_fun[\"BCE_loss\"]\n",
        "            )\n",
        "            if epoch%2==0:\n",
        "                for item in test_dataloader:\n",
        "                    test_measure_mean, test_measure_std, miou = test(model, device, test_dataloader[item], epoch, perf, f\"Test {item}\", verbose=False)\n",
        "                    Dices.append(test_measure_mean)\n",
        "                    mIOUs.append(miou)\n",
        "                t = Texttable()\n",
        "                t.add_rows([['','Kvasir', 'ETIS', 'CVC-ColonDB', 'CVC-ClinicDB', \"CVC-T\"], Dices, mIOUs])\n",
        "                print(t.draw())\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Training interrupted by user\")\n",
        "            sys.exit(0)\n",
        "        if args.lrs == \"true\":\n",
        "            if args.type_lr == \"LROnP\":\n",
        "                scheduler.step(test_measure_mean)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "        if prev_best_test == None or test_measure_mean > prev_best_test:\n",
        "            print(\"Saving...\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"model_state_dict\": model.state_dict()\n",
        "                    if args.mgpu == \"false\"\n",
        "                    else model.module.state_dict(),\n",
        "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                    \"scheduler\":scheduler.state_dict(),\n",
        "                    \"test_measure_mean\": test_measure_mean,\n",
        "                    \"test_measure_std\": test_measure_std,\n",
        "                },\n",
        "                f\"./Trained models/CTDCformer_epoch_backbonePvitB4_\" + args.dataset + \".pt\",\n",
        "            )\n",
        "            prev_best_test = test_measure_mean\n",
        "\n",
        "\n",
        "def main():\n",
        "    train(args)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "LMs20ZBv4vpZ",
        "outputId": "bd80f36b-5245-4e9f-fdb3-62c6e34e9f2e",
        "papermill": {
          "duration": 33096.966842,
          "end_time": "2022-12-21T10:24:11.906876",
          "exception": false,
          "start_time": "2022-12-21T01:12:34.940034",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-01-18T12:52:33.145425Z",
          "iopub.execute_input": "2023-01-18T12:52:33.146157Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best test: None epoch: 0\n",
            "Train Epoch: 1 [1448/1450 (100.0%)]\tAverage loss: 1.030646\tTime: 972.186861\n",
            "Saving...\n",
            "Train Epoch: 2 [1448/1450 (100.0%)]\tAverage loss: 1.005000\tTime: 970.547182\n",
            "+------+--------+-------+-------------+--------------+-------+\n",
            "|      | Kvasir | ETIS  | CVC-ColonDB | CVC-ClinicDB | CVC-T |\n",
            "+======+========+=======+=============+==============+=======+\n",
            "| Dice | 0.435  | 0.152 | 0.188       | 0.327        | 0.191 |\n",
            "+------+--------+-------+-------------+--------------+-------+\n",
            "| mIOU | 0.307  | 0.095 | 0.124       | 0.225        | 0.120 |\n",
            "+------+--------+-------+-------------+--------------+-------+\n",
            "Saving...\n",
            "Train Epoch: 3 [1448/1450 (100.0%)]\tAverage loss: 0.980739\tTime: 969.834227\n",
            "Train Epoch: 4 [1448/1450 (100.0%)]\tAverage loss: 0.956448\tTime: 969.470568\n",
            "+------+--------+-------+-------------+--------------+-------+\n",
            "|      | Kvasir | ETIS  | CVC-ColonDB | CVC-ClinicDB | CVC-T |\n",
            "+======+========+=======+=============+==============+=======+\n",
            "| Dice | 0.426  | 0.157 | 0.153       | 0.389        | 0.143 |\n",
            "+------+--------+-------+-------------+--------------+-------+\n",
            "| mIOU | 0.303  | 0.095 | 0.099       | 0.277        | 0.086 |\n",
            "+------+--------+-------+-------------+--------------+-------+\n",
            "Train Epoch: 5 [664/1450 (45.9%)]\tLoss: 0.856544\tTime: 445.406086"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_image(image):\n",
        "    predicted_map = np.array(image.detach().cpu())\n",
        "    predicted_map = np.squeeze(predicted_map)\n",
        "    predicted_map = predicted_map > 0\n",
        "    return predicted_map\n",
        "  \n",
        "def saveImage(data, label, predict, path):\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(data)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(label, cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(predict, cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.savefig(path)\n",
        "\n",
        "def predict():\n",
        "    \n",
        "    if not os.path.exists(\"./Predictions\"):\n",
        "        os.makedirs(\"./Predictions\")\n",
        "    if not os.path.exists(\"./Predictions/Trained on {}\".format(\"Kvar\")):\n",
        "        os.makedirs(\"./Predictions/Trained on {}\".format(\"Kvar\"))\n",
        "    \n",
        "    t = time.time()\n",
        "    model.eval()\n",
        "    checkpoint = torch.load(\"./Trained models/CTDCformer_epoch_backbonePvitB4_Kvasir.pt\")\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    perf_accumulator = []\n",
        "    mIOU = []\n",
        "    Dice = []\n",
        "    for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        perf_accumulator.append(perf(output, target).item())\n",
        "        mIOU.append(Fmstric.binary_jaccard_index(torch.sigmoid(output), target>0.5).item())\n",
        "        Dice.append(torchmetrics.functional.dice(torch.sigmoid(output), target>0.5).item())\n",
        "        input_image = data[0].permute(1,2,0).cpu().numpy()\n",
        "        labels = postprocess_image(target)\n",
        "        predicted_map = postprocess_image(output)\n",
        "        saveImage(input_image, labels, predicted_map, \"./Predictions/Trained on {}/dice_{}_{}.jpg\".format(\n",
        "                \"Kvar\",perf_accumulator[-1], batch_idx))\n",
        "        # cv2.imwrite(\n",
        "        #     \"/content/drive/MyDrive/Predictions/Trained on {}/dice_{}_{}.jpg\".format(\n",
        "        #         \"Kvar\",perf_accumulator[-1], batch_idx),\n",
        "        #     predicted_map * 255,\n",
        "        # )\n",
        "\n",
        "        if batch_idx + 1 < len(test_dataloader):\n",
        "            print(\n",
        "                \"\\r{}  Epoch: {} [{}/{} ({:.1f}%)]\\tDice: {:.6f}\\tmIOU: {:.6f}\\tDice: {:.6f}\\tTime: {:.6f}\".format(\n",
        "                    \"Predict\", 0, batch_idx + 1, len(test_dataloader), 100.0 * (batch_idx + 1) / len(test_dataloader),\n",
        "                    np.mean(perf_accumulator), np.mean(mIOU), np.mean(Dice), time.time() - t, ), end=\"\", )\n",
        "        else:\n",
        "            print(\n",
        "                \"\\r{}  Epoch: {} [{}/{} ({:.1f}%)]\\tDice: {:.6f}\\tmIOU: {:.6f}\\tDice: {:.6f}\\tTime: {:.6f}\".format(\n",
        "                    \"Predict\",0, batch_idx + 1, len(test_dataloader), 100.0 * (batch_idx + 1) / len(test_dataloader),\n",
        "                    np.mean(perf_accumulator), np.mean(mIOU), np.mean(Dice), time.time() - t, ))\n",
        "\n",
        "    return np.mean(perf_accumulator), np.std(perf_accumulator)"
      ],
      "metadata": {
        "id": "fRAea-7BNry1",
        "papermill": {
          "duration": 1.788313,
          "end_time": "2022-12-21T10:24:15.500438",
          "exception": false,
          "start_time": "2022-12-21T10:24:13.712125",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict()"
      ],
      "metadata": {
        "id": "MJ1U-GgjFwFy",
        "papermill": {
          "duration": 1.526925,
          "end_time": "2022-12-21T10:24:18.662080",
          "exception": false,
          "start_time": "2022-12-21T10:24:17.135155",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.subplot(1,3,1)\n",
        "# plt.imshow(img1, cmap=\"gray\")\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])\n",
        "# plt.subplot(1,3,2)\n",
        "# plt.imshow(img2, cmap=\"gray\")\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])\n",
        "# plt.subplot(1,3,3)\n",
        "# plt.imshow(img3, cmap=\"gray\")\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])\n",
        "# plt.savefig(\"test.png\")"
      ],
      "metadata": {
        "id": "3z4CPcJUH_OL",
        "papermill": {
          "duration": 1.576701,
          "end_time": "2022-12-21T10:24:21.875499",
          "exception": false,
          "start_time": "2022-12-21T10:24:20.298798",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgQMS-cXI8sE",
        "papermill": {
          "duration": 1.623893,
          "end_time": "2022-12-21T10:24:25.114582",
          "exception": false,
          "start_time": "2022-12-21T10:24:23.490689",
          "status": "completed"
        },
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}